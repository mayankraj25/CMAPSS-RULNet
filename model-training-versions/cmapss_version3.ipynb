{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fbbfeb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:38.187186Z",
     "iopub.status.busy": "2025-12-11T07:28:38.186925Z",
     "iopub.status.idle": "2025-12-11T07:28:56.115735Z",
     "shell.execute_reply": "2025-12-11T07:28:56.115121Z"
    },
    "papermill": {
     "duration": 17.933293,
     "end_time": "2025-12-11T07:28:56.117191",
     "exception": false,
     "start_time": "2025-12-11T07:28:38.183898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 07:28:41.372009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765438121.559506      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765438121.614603      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7a2299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:56.122681Z",
     "iopub.status.busy": "2025-12-11T07:28:56.122292Z",
     "iopub.status.idle": "2025-12-11T07:28:56.131343Z",
     "shell.execute_reply": "2025-12-11T07:28:56.130627Z"
    },
    "papermill": {
     "duration": 0.012759,
     "end_time": "2025-12-11T07:28:56.132338",
     "exception": false,
     "start_time": "2025-12-11T07:28:56.119579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_FD001.txt']\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/kaggle/input/cmapss1\"\n",
    "print(os.listdir(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f008568f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:56.136745Z",
     "iopub.status.busy": "2025-12-11T07:28:56.136566Z",
     "iopub.status.idle": "2025-12-11T07:28:56.141161Z",
     "shell.execute_reply": "2025-12-11T07:28:56.140642Z"
    },
    "papermill": {
     "duration": 0.008053,
     "end_time": "2025-12-11T07:28:56.142201",
     "exception": false,
     "start_time": "2025-12-11T07:28:56.134148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_process_data(filepath):\n",
    "    print(f\"Loading data from {filepath}...\")\n",
    "    \n",
    "    cols = ['id', 'cycle', 'setting1', 'setting2', 'setting3'] + [f's{i}' for i in range(1, 22)]\n",
    "    \n",
    "    data = pd.read_csv(filepath, sep='\\s+', header=None, names=cols)\n",
    "    print(f\"Original Data Shape: {data.shape}\")\n",
    "\n",
    "    # RUL\n",
    "    rul = data.groupby('id')['cycle'].max().reset_index()\n",
    "    rul.columns = ['id', 'max']\n",
    "    data = data.merge(rul, on='id', how='left')\n",
    "    data['RUL'] = data['max'] - data['cycle']\n",
    "    data.drop('max', axis=1, inplace=True)\n",
    "    \n",
    "    print(\"RUL Calculation Complete.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027d48ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:56.147000Z",
     "iopub.status.busy": "2025-12-11T07:28:56.146560Z",
     "iopub.status.idle": "2025-12-11T07:28:56.151492Z",
     "shell.execute_reply": "2025-12-11T07:28:56.150988Z"
    },
    "papermill": {
     "duration": 0.008387,
     "end_time": "2025-12-11T07:28:56.152484",
     "exception": false,
     "start_time": "2025-12-11T07:28:56.144097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_for_training(data, sequence_length=50):\n",
    "    print(\"Starting Normalization and Windowing...\")\n",
    "    # Excluding ID, Cycle,RUL \n",
    "    train_cols = [col for col in data.columns if col not in ['id', 'cycle', 'RUL']]\n",
    "    \n",
    "    # Normalize0-1\n",
    "    scaler = MinMaxScaler()\n",
    "    data[train_cols] = scaler.fit_transform(data[train_cols])\n",
    "    print(\"Data Normalized.\")\n",
    "\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for engine_id in data['id'].unique():\n",
    "        engine_data = data[data['id'] == engine_id]\n",
    "        \n",
    "        features = engine_data[train_cols].values\n",
    "        target = engine_data['RUL'].values\n",
    "        \n",
    "        if len(engine_data) < sequence_length:\n",
    "            continue\n",
    "            \n",
    "        for i in range(len(engine_data) - sequence_length):\n",
    "            window_data = features[i : i + sequence_length]\n",
    "            label_value = target[i + sequence_length]\n",
    "            \n",
    "            sequences.append(window_data)\n",
    "            labels.append(label_value)\n",
    "            \n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03acc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:56.157076Z",
     "iopub.status.busy": "2025-12-11T07:28:56.156664Z",
     "iopub.status.idle": "2025-12-11T07:28:56.161350Z",
     "shell.execute_reply": "2025-12-11T07:28:56.160819Z"
    },
    "papermill": {
     "duration": 0.008145,
     "end_time": "2025-12-11T07:28:56.162397",
     "exception": false,
     "start_time": "2025-12-11T07:28:56.154252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Optimized Neural Network Architecture.\n",
    "    Changes: Increased units, added BatchNormalization, and L2 Regularization.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Layer 1: Wider LSTM (128 units) + L2 Regularization\n",
    "        LSTM(units=128, return_sequences=True, input_shape=input_shape, \n",
    "             kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(), \n",
    "        Dropout(0.3),         # Increased dropout to fight overfitting\n",
    "        \n",
    "        # Layer 2: Deep LSTM (64 units)\n",
    "        LSTM(units=64, return_sequences=True, kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Layer 3: Final LSTM (32 units) \n",
    "        LSTM(units=32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output Layer\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        loss='mean_squared_error', \n",
    "        metrics=['mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99f4480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:28:56.166961Z",
     "iopub.status.busy": "2025-12-11T07:28:56.166544Z",
     "iopub.status.idle": "2025-12-11T07:31:44.602295Z",
     "shell.execute_reply": "2025-12-11T07:31:44.601644Z"
    },
    "papermill": {
     "duration": 168.439443,
     "end_time": "2025-12-11T07:31:44.603658",
     "exception": false,
     "start_time": "2025-12-11T07:28:56.164215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /kaggle/input/cmapss1/train_FD001.txt...\n",
      "Original Data Shape: (20631, 26)\n",
      "RUL Calculation Complete.\n",
      "Starting Normalization and Windowing...\n",
      "Data Normalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765438137.326032      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optimized Training...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765438142.797511      61 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 8734.5459 - mae: 75.3386 - rmse: 93.4196 - val_loss: 9955.7285 - val_mae: 77.7182 - val_rmse: 99.7774 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 6531.4419 - mae: 61.6680 - rmse: 80.8064 - val_loss: 13343.0918 - val_mae: 95.0364 - val_rmse: 115.5114 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 5357.7129 - mae: 53.1248 - rmse: 73.1723 - val_loss: 6695.8828 - val_mae: 58.5845 - val_rmse: 81.8269 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 4163.6494 - mae: 44.7736 - rmse: 64.5163 - val_loss: 5579.0400 - val_mae: 52.6633 - val_rmse: 74.6913 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 3398.1924 - mae: 38.4340 - rmse: 58.2766 - val_loss: 5042.9419 - val_mae: 51.3030 - val_rmse: 71.0118 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 2754.3799 - mae: 33.5510 - rmse: 52.4635 - val_loss: 3980.9565 - val_mae: 42.4270 - val_rmse: 63.0926 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 2112.3818 - mae: 28.3346 - rmse: 45.9520 - val_loss: 3652.1677 - val_mae: 41.5778 - val_rmse: 60.4307 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 1835.2102 - mae: 26.4239 - rmse: 42.8288 - val_loss: 2846.2605 - val_mae: 34.3027 - val_rmse: 53.3475 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 1499.4485 - mae: 23.3943 - rmse: 38.7103 - val_loss: 2569.4744 - val_mae: 32.5465 - val_rmse: 50.6867 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 1310.4833 - mae: 21.4029 - rmse: 36.1864 - val_loss: 2154.0999 - val_mae: 28.8943 - val_rmse: 46.4085 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1161.2743 - mae: 20.0776 - rmse: 34.0575 - val_loss: 1919.2837 - val_mae: 28.3715 - val_rmse: 43.8054 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 1008.1805 - mae: 19.1048 - rmse: 31.7342 - val_loss: 1785.5360 - val_mae: 28.1436 - val_rmse: 42.2509 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 891.4161 - mae: 18.0215 - rmse: 29.8463 - val_loss: 1580.2102 - val_mae: 25.5971 - val_rmse: 39.7465 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 836.6094 - mae: 17.5260 - rmse: 28.9035 - val_loss: 1704.2515 - val_mae: 28.1332 - val_rmse: 41.2771 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 747.7285 - mae: 16.5693 - rmse: 27.3310 - val_loss: 1350.7194 - val_mae: 25.0392 - val_rmse: 36.7455 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 676.3760 - mae: 16.1969 - rmse: 25.9811 - val_loss: 1869.7716 - val_mae: 30.6823 - val_rmse: 43.2349 - learning_rate: 0.0010\n",
      "Epoch 17/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 687.0320 - mae: 16.2662 - rmse: 26.1916 - val_loss: 1230.2089 - val_mae: 23.5283 - val_rmse: 35.0665 - learning_rate: 0.0010\n",
      "Epoch 18/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 630.4667 - mae: 15.5969 - rmse: 25.0852 - val_loss: 1198.3722 - val_mae: 22.9932 - val_rmse: 34.6091 - learning_rate: 0.0010\n",
      "Epoch 19/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 557.7518 - mae: 14.7414 - rmse: 23.5929 - val_loss: 1130.9180 - val_mae: 23.2756 - val_rmse: 33.6201 - learning_rate: 0.0010\n",
      "Epoch 20/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 516.0043 - mae: 14.4175 - rmse: 22.6971 - val_loss: 1208.1022 - val_mae: 23.3910 - val_rmse: 34.7485 - learning_rate: 0.0010\n",
      "Epoch 21/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 463.0154 - mae: 13.5530 - rmse: 21.4954 - val_loss: 1632.1229 - val_mae: 27.2597 - val_rmse: 40.3913 - learning_rate: 0.0010\n",
      "Epoch 22/40\n",
      "\u001b[1m439/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 464.9968 - mae: 13.5435 - rmse: 21.5378\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 464.8870 - mae: 13.5423 - rmse: 21.5353 - val_loss: 1787.5479 - val_mae: 28.0879 - val_rmse: 42.2712 - learning_rate: 0.0010\n",
      "Epoch 23/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 394.6516 - mae: 12.5846 - rmse: 19.8450 - val_loss: 1711.2026 - val_mae: 26.1268 - val_rmse: 41.3582 - learning_rate: 5.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 366.2993 - mae: 12.0573 - rmse: 19.1119 - val_loss: 1583.4950 - val_mae: 25.5325 - val_rmse: 39.7843 - learning_rate: 5.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m438/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 336.5697 - mae: 11.5770 - rmse: 18.3211\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 336.6687 - mae: 11.5786 - rmse: 18.3238 - val_loss: 1589.1576 - val_mae: 24.2455 - val_rmse: 39.8553 - learning_rate: 5.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 324.2419 - mae: 11.4458 - rmse: 17.9786 - val_loss: 1562.9656 - val_mae: 25.3085 - val_rmse: 39.5253 - learning_rate: 2.5000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 326.7384 - mae: 11.3032 - rmse: 18.0503 - val_loss: 1479.4200 - val_mae: 22.8307 - val_rmse: 38.4539 - learning_rate: 2.5000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m436/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 300.5697 - mae: 10.9927 - rmse: 17.3134\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 300.5990 - mae: 10.9930 - rmse: 17.3143 - val_loss: 1368.7018 - val_mae: 23.7383 - val_rmse: 36.9863 - learning_rate: 2.5000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 304.3834 - mae: 10.8999 - rmse: 17.4151 - val_loss: 1500.8069 - val_mae: 24.1722 - val_rmse: 38.7310 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '/kaggle/input/cmapss1/train_FD001.txt' \n",
    "    \n",
    "SEQUENCE_LENGTH = 50\n",
    "\n",
    "df = load_and_process_data(FILE_PATH)\n",
    "\n",
    "X_train, y_train = process_for_training(df, SEQUENCE_LENGTH)\n",
    "\n",
    "model = create_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Optimized Training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,            # Increased epochs because we have EarlyStopping\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[lr_scheduler, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9b39ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:31:44.908080Z",
     "iopub.status.busy": "2025-12-11T07:31:44.907452Z",
     "iopub.status.idle": "2025-12-11T07:31:44.926233Z",
     "shell.execute_reply": "2025-12-11T07:31:44.925546Z"
    },
    "papermill": {
     "duration": 0.212364,
     "end_time": "2025-12-11T07:31:44.927359",
     "exception": false,
     "start_time": "2025-12-11T07:31:44.714995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m78,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,117</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m422,117\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,577</span> (549.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140,577\u001b[0m (549.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281,156</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m281,156\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8971659,
     "sourceId": 14089994,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 192.973435,
   "end_time": "2025-12-11T07:31:47.657978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T07:28:34.684543",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
